{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "import numpy as np\n",
    "\n",
    "def midi_to_notes(midi_file):\n",
    "    midi = music21.converter.parse(midi_file)\n",
    "    notes = []\n",
    "    for element in midi.flat.notes:\n",
    "        if isinstance(element, music21.note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, music21.chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    return notes\n",
    "\n",
    "# Example usage:\n",
    "# notes = midi_to_notes('path/to/midi/file.mid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Embedding, MultiHeadAttention, LayerNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1])(x)\n",
    "    return x + res\n",
    "\n",
    "def build_transformer_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    for dim in mlp_units:\n",
    "        x = Dense(dim, activation=\"relu\")(x)\n",
    "        x = Dropout(mlp_dropout)(x)\n",
    "    outputs = Dense(input_shape[0], activation=\"softmax\")(x)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Define constants\n",
    "SEQ_LENGTH = 100  # Sequence length\n",
    "VOCAB_SIZE = 128  # Number of unique notes\n",
    "\n",
    "# Build the model\n",
    "model = build_transformer_model(\n",
    "    input_shape=(SEQ_LENGTH, VOCAB_SIZE),\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=256,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[256],\n",
    "    dropout=0.1,\n",
    "    mlp_dropout=0.1,\n",
    ")\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, seq_length):\n",
    "    pitch_names = sorted(set(notes))\n",
    "    note_to_int = {note: number for number, note in enumerate(pitch_names)}\n",
    "    \n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    \n",
    "    for i in range(0, len(notes) - seq_length):\n",
    "        seq_in = notes[i:i + seq_length]\n",
    "        seq_out = notes[i + seq_length]\n",
    "        network_input.append([note_to_int[char] for char in seq_in])\n",
    "        network_output.append(note_to_int[seq_out])\n",
    "    \n",
    "    n_patterns = len(network_input)\n",
    "    \n",
    "    network_input = np.reshape(network_input, (n_patterns, seq_length, 1))\n",
    "    network_output = np.array(network_output)\n",
    "    \n",
    "    return network_input, network_output\n",
    "\n",
    "# Prepare data\n",
    "# notes = midi_to_notes('path/to/midi/file.mid')\n",
    "# X, y = prepare_sequences(notes, SEQ_LENGTH)\n",
    "\n",
    "# Train the model\n",
    "# model.fit(X, y, epochs=100, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, start_sequence, num_generate, pitch_names):\n",
    "    int_to_note = {number: note for number, note in enumerate(pitch_names)}\n",
    "    note_to_int = {note: number for number, note in enumerate(pitch_names)}\n",
    "    \n",
    "    pattern = [note_to_int[char] for char in start_sequence]\n",
    "    prediction_output = []\n",
    "\n",
    "    for note_index in range(num_generate):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "    \n",
    "    return prediction_output\n",
    "\n",
    "# Example usage:\n",
    "# start_sequence = notes[:SEQ_LENGTH]\n",
    "# generated_notes = generate_notes(model, start_sequence, 500, pitch_names)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
